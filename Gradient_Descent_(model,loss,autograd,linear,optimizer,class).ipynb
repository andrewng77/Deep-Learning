{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent (model,loss,autograd,linear,optimizer,class)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3sluRi8c3lkS8D5hSErSr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsPfFUh0D-cJ",
        "colab_type": "text"
      },
      "source": [
        "Gradient Descent - Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOXi9NWypGxO",
        "colab_type": "text"
      },
      "source": [
        "## GENERAL Step by step <p>\n",
        "1) Design model ( input, output size, forward pass )<p>\n",
        "2) Construct loss and optimizer<p>\n",
        "3) Training loop<p>\n",
        "\n",
        "- forward pass : compute prediction\n",
        "- backward pass : gradients\n",
        "- update weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lpOlkuS5zIG",
        "colab_type": "text"
      },
      "source": [
        "# Add Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Jiz5Gd9PUy",
        "colab_type": "code",
        "outputId": "d2b48bbf-104c-435f-9898-47c4b41ef7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1,2,3,4],dtype = torch.float32)\n",
        "Y = torch.tensor([2,4,6,8],dtype = torch.float32)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0,dtype = torch.float32, requires_grad=True) \n",
        "print(w)\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_hat):\n",
        "  return ((y_hat - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training : f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = forward(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  print(w.grad)\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad(): #ensure the gradient is not calculated\n",
        "    w.sub_(learning_rate*w.grad)\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  w.grad.zero_() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    print(f'epoch: {epoch+1}, weight : {w:.3f}, loss ={l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {forward(5):.3f}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0., requires_grad=True)\n",
            "Prediction before training : f(5) = 0.000\n",
            "tensor(-30.)\n",
            "epoch: 1, weight : 0.300, loss =30.00000000\n",
            "tensor(-25.5000)\n",
            "tensor(-21.6750)\n",
            "tensor(-18.4238)\n",
            "tensor(-15.6602)\n",
            "tensor(-13.3112)\n",
            "tensor(-11.3145)\n",
            "tensor(-9.6173)\n",
            "tensor(-8.1747)\n",
            "tensor(-6.9485)\n",
            "tensor(-5.9062)\n",
            "epoch: 11, weight : 1.665, loss =1.16278565\n",
            "tensor(-5.0203)\n",
            "tensor(-4.2673)\n",
            "tensor(-3.6272)\n",
            "tensor(-3.0831)\n",
            "tensor(-2.6206)\n",
            "tensor(-2.2275)\n",
            "tensor(-1.8934)\n",
            "tensor(-1.6094)\n",
            "tensor(-1.3680)\n",
            "tensor(-1.1628)\n",
            "epoch: 21, weight : 1.934, loss =0.04506890\n",
            "tensor(-0.9884)\n",
            "tensor(-0.8401)\n",
            "tensor(-0.7141)\n",
            "tensor(-0.6070)\n",
            "tensor(-0.5159)\n",
            "tensor(-0.4385)\n",
            "tensor(-0.3728)\n",
            "tensor(-0.3168)\n",
            "tensor(-0.2693)\n",
            "tensor(-0.2289)\n",
            "epoch: 31, weight : 1.987, loss =0.00174685\n",
            "tensor(-0.1946)\n",
            "tensor(-0.1654)\n",
            "tensor(-0.1406)\n",
            "tensor(-0.1195)\n",
            "tensor(-0.1016)\n",
            "tensor(-0.0863)\n",
            "tensor(-0.0734)\n",
            "tensor(-0.0624)\n",
            "tensor(-0.0530)\n",
            "tensor(-0.0451)\n",
            "epoch: 41, weight : 1.997, loss =0.00006770\n",
            "tensor(-0.0383)\n",
            "tensor(-0.0326)\n",
            "tensor(-0.0277)\n",
            "tensor(-0.0235)\n",
            "tensor(-0.0200)\n",
            "tensor(-0.0170)\n",
            "tensor(-0.0144)\n",
            "tensor(-0.0123)\n",
            "tensor(-0.0104)\n",
            "tensor(-0.0089)\n",
            "epoch: 51, weight : 1.999, loss =0.00000262\n",
            "tensor(-0.0075)\n",
            "tensor(-0.0064)\n",
            "tensor(-0.0054)\n",
            "tensor(-0.0046)\n",
            "tensor(-0.0039)\n",
            "tensor(-0.0033)\n",
            "tensor(-0.0028)\n",
            "tensor(-0.0024)\n",
            "tensor(-0.0021)\n",
            "tensor(-0.0017)\n",
            "epoch: 61, weight : 2.000, loss =0.00000010\n",
            "tensor(-0.0015)\n",
            "tensor(-0.0013)\n",
            "tensor(-0.0011)\n",
            "tensor(-0.0009)\n",
            "tensor(-0.0008)\n",
            "tensor(-0.0007)\n",
            "tensor(-0.0006)\n",
            "tensor(-0.0005)\n",
            "tensor(-0.0004)\n",
            "tensor(-0.0003)\n",
            "epoch: 71, weight : 2.000, loss =0.00000000\n",
            "tensor(-0.0003)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0001)\n",
            "tensor(-0.0001)\n",
            "tensor(-9.2983e-05)\n",
            "tensor(-7.8678e-05)\n",
            "tensor(-6.6340e-05)\n",
            "epoch: 81, weight : 2.000, loss =0.00000000\n",
            "tensor(-5.5254e-05)\n",
            "tensor(-4.6849e-05)\n",
            "tensor(-3.8981e-05)\n",
            "tensor(-3.3796e-05)\n",
            "tensor(-2.8610e-05)\n",
            "tensor(-2.4676e-05)\n",
            "tensor(-2.1458e-05)\n",
            "tensor(-1.8239e-05)\n",
            "tensor(-1.4305e-05)\n",
            "tensor(-1.2338e-05)\n",
            "epoch: 91, weight : 2.000, loss =0.00000000\n",
            "tensor(-1.0371e-05)\n",
            "tensor(-9.1195e-06)\n",
            "tensor(-7.1526e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "Prediction after training : f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWWlHKor58OF",
        "colab_type": "text"
      },
      "source": [
        "# Add optimizer,nn.Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjhY6JHvB0S8",
        "colab_type": "code",
        "outputId": "b80db3b3-04ef-46bd-b61c-04626abdcb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "# test sample\n",
        "X_test = torch.tensor([5],dtype = torch.float32)\n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# Loss\n",
        "loss = nn.MSELoss() \n",
        "\n",
        "# optimzie the weights\n",
        "# bias all included\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  print(w.grad)\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "  \n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  w.grad.zero_() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    [w,b] = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w[0][0].item():.3f}, loss ={l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n",
            "Prediction before training : f(5) = 0.081\n",
            "tensor(0.)\n",
            "epoch: 1, weight : 0.265, loss =28.65767860\n",
            "tensor([[-24.4345]])\n",
            "tensor([[-20.3674]])\n",
            "tensor([[-16.9795]])\n",
            "tensor([[-14.1573]])\n",
            "tensor([[-11.8064]])\n",
            "tensor([[-9.8481]])\n",
            "tensor([[-8.2168]])\n",
            "tensor([[-6.8579]])\n",
            "tensor([[-5.7259]])\n",
            "tensor([[-4.7829]])\n",
            "epoch: 11, weight : 1.497, loss =0.84330875\n",
            "tensor([[-3.9973]])\n",
            "tensor([[-3.3429]])\n",
            "tensor([[-2.7978]])\n",
            "tensor([[-2.3437]])\n",
            "tensor([[-1.9653]])\n",
            "tensor([[-1.6501]])\n",
            "tensor([[-1.3875]])\n",
            "tensor([[-1.1688]])\n",
            "tensor([[-0.9865]])\n",
            "tensor([[-0.8346]])\n",
            "epoch: 21, weight : 1.702, loss =0.11775488\n",
            "tensor([[-0.7081]])\n",
            "tensor([[-0.6026]])\n",
            "tensor([[-0.5147]])\n",
            "tensor([[-0.4415]])\n",
            "tensor([[-0.3804]])\n",
            "tensor([[-0.3295]])\n",
            "tensor([[-0.2871]])\n",
            "tensor([[-0.2517]])\n",
            "tensor([[-0.2222]])\n",
            "tensor([[-0.1976]])\n",
            "epoch: 31, weight : 1.741, loss =0.09339909\n",
            "tensor([[-0.1771]])\n",
            "tensor([[-0.1599]])\n",
            "tensor([[-0.1456]])\n",
            "tensor([[-0.1336]])\n",
            "tensor([[-0.1236]])\n",
            "tensor([[-0.1152]])\n",
            "tensor([[-0.1082]])\n",
            "tensor([[-0.1023]])\n",
            "tensor([[-0.0974]])\n",
            "tensor([[-0.0933]])\n",
            "epoch: 41, weight : 1.754, loss =0.08750996\n",
            "tensor([[-0.0898]])\n",
            "tensor([[-0.0868]])\n",
            "tensor([[-0.0844]])\n",
            "tensor([[-0.0822]])\n",
            "tensor([[-0.0805]])\n",
            "tensor([[-0.0789]])\n",
            "tensor([[-0.0776]])\n",
            "tensor([[-0.0765]])\n",
            "tensor([[-0.0755]])\n",
            "tensor([[-0.0747]])\n",
            "epoch: 51, weight : 1.762, loss =0.08240467\n",
            "tensor([[-0.0739]])\n",
            "tensor([[-0.0733]])\n",
            "tensor([[-0.0727]])\n",
            "tensor([[-0.0722]])\n",
            "tensor([[-0.0717]])\n",
            "tensor([[-0.0713]])\n",
            "tensor([[-0.0709]])\n",
            "tensor([[-0.0706]])\n",
            "tensor([[-0.0702]])\n",
            "tensor([[-0.0699]])\n",
            "epoch: 61, weight : 1.769, loss =0.07760802\n",
            "tensor([[-0.0696]])\n",
            "tensor([[-0.0694]])\n",
            "tensor([[-0.0691]])\n",
            "tensor([[-0.0688]])\n",
            "tensor([[-0.0686]])\n",
            "tensor([[-0.0683]])\n",
            "tensor([[-0.0681]])\n",
            "tensor([[-0.0679]])\n",
            "tensor([[-0.0677]])\n",
            "tensor([[-0.0674]])\n",
            "epoch: 71, weight : 1.776, loss =0.07309083\n",
            "tensor([[-0.0672]])\n",
            "tensor([[-0.0670]])\n",
            "tensor([[-0.0668]])\n",
            "tensor([[-0.0666]])\n",
            "tensor([[-0.0664]])\n",
            "tensor([[-0.0662]])\n",
            "tensor([[-0.0660]])\n",
            "tensor([[-0.0658]])\n",
            "tensor([[-0.0656]])\n",
            "tensor([[-0.0654]])\n",
            "epoch: 81, weight : 1.782, loss =0.06883656\n",
            "tensor([[-0.0652]])\n",
            "tensor([[-0.0650]])\n",
            "tensor([[-0.0648]])\n",
            "tensor([[-0.0646]])\n",
            "tensor([[-0.0644]])\n",
            "tensor([[-0.0642]])\n",
            "tensor([[-0.0640]])\n",
            "tensor([[-0.0638]])\n",
            "tensor([[-0.0636]])\n",
            "tensor([[-0.0634]])\n",
            "epoch: 91, weight : 1.789, loss =0.06482991\n",
            "tensor([[-0.0633]])\n",
            "tensor([[-0.0631]])\n",
            "tensor([[-0.0629]])\n",
            "tensor([[-0.0627]])\n",
            "tensor([[-0.0625]])\n",
            "tensor([[-0.0623]])\n",
            "tensor([[-0.0621]])\n",
            "tensor([[-0.0619]])\n",
            "tensor([[-0.0618]])\n",
            "Prediction after training : f(5) = 9.576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7is8wXS6E9O",
        "colab_type": "text"
      },
      "source": [
        "# Add nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVc-QVxmkPEd",
        "colab_type": "code",
        "outputId": "88d73a33-8e16-4ffe-e32d-553eca6e9c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#1) Design model ( input, output size, forward pass )\n",
        "#2) Construct loss and optimizer\n",
        "#3) Training loop\n",
        "#forward pass : compute prediction\n",
        "#backward pass : gradients\n",
        "#update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([[5]],dtype = torch.float32)\n",
        "n_samples,n_features = X.shape\n",
        "print(X.shape)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad=True) \n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# loss = MSE\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  #with torch.no_grad(): #ensure the gradient is not calculated\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  optimizer.zero_grad() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    w,b = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w.item():.3f}, loss ={l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "Prediction before training : f(5) = -4.077\n",
            "epoch: 1, weight : -0.570, loss =55.11408615\n",
            "epoch: 11, weight : 1.140, loss =1.83126807\n",
            "epoch: 21, weight : 1.428, loss =0.42912209\n",
            "epoch: 31, weight : 1.487, loss =0.37062573\n",
            "epoch: 41, weight : 1.509, loss =0.34818617\n",
            "epoch: 51, weight : 1.525, loss =0.32789737\n",
            "epoch: 61, weight : 1.539, loss =0.30881146\n",
            "epoch: 71, weight : 1.553, loss =0.29083693\n",
            "epoch: 81, weight : 1.566, loss =0.27390882\n",
            "epoch: 91, weight : 1.579, loss =0.25796592\n",
            "Prediction after training : f(5) = 9.155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWT1MpCD6uCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Add Class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lojngyRssEnk",
        "colab_type": "code",
        "outputId": "7894ca6f-e01b-473f-b221-ff04983d26de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#1) Design model ( input, output size, forward pass )\n",
        "#2) Construct loss and optimizer\n",
        "#3) Training loop\n",
        "#forward pass : compute prediction\n",
        "#backward pass : gradients\n",
        "#update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([[5]],dtype = torch.float32)\n",
        "n_samples,n_features = X.shape\n",
        "print(X.shape)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "#model = nn.Linear(input_size,output_size)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad=True) \n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim,output_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size,output_size)\n",
        "\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# loss = MSE\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  #with torch.no_grad(): #ensure the gradient is not calculated\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  optimizer.zero_grad() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    w,b = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w.item():.3f}, loss ={l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "Prediction before training : f(5) = 3.155\n",
            "epoch: 1, weight : 0.668, loss =12.13250446\n",
            "epoch: 11, weight : 1.470, loss =0.51648831\n",
            "epoch: 21, weight : 1.608, loss =0.20416233\n",
            "epoch: 31, weight : 1.639, loss =0.18497618\n",
            "epoch: 41, weight : 1.653, loss =0.17402071\n",
            "epoch: 51, weight : 1.664, loss =0.16388685\n",
            "epoch: 61, weight : 1.674, loss =0.15434767\n",
            "epoch: 71, weight : 1.684, loss =0.14536379\n",
            "epoch: 81, weight : 1.693, loss =0.13690287\n",
            "epoch: 91, weight : 1.702, loss =0.12893438\n",
            "Prediction after training : f(5) = 9.403\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}