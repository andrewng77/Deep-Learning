{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent (model,loss,autograd,linear,optimizer,class)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWTU8eYC5hcY8GqcWoXbIU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsPfFUh0D-cJ",
        "colab_type": "text"
      },
      "source": [
        "Gradient Descent - Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOXi9NWypGxO",
        "colab_type": "text"
      },
      "source": [
        "## GENERAL Step by step <p>\n",
        "1) Design model ( input, output size, forward pass )<p>\n",
        "2) Construct loss and optimizer<p>\n",
        "3) Training loop<p>\n",
        "\n",
        "- forward pass : compute prediction\n",
        "- backward pass : gradients\n",
        "- update weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lpOlkuS5zIG",
        "colab_type": "text"
      },
      "source": [
        "# Add Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Jiz5Gd9PUy",
        "colab_type": "code",
        "outputId": "48671565-c852-42f1-d829-47939249d33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1,2,3,4],dtype = torch.float32)\n",
        "Y = torch.tensor([2,4,6,8],dtype = torch.float32)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0,dtype = torch.float32, requires_grad=True) \n",
        "print(w)\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_hat):\n",
        "  return ((y_hat - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training : f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = forward(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  print(w.grad)\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad(): #ensure the gradient is not calculated\n",
        "    w.sub_(learning_rate*w.grad)\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  w.grad.zero_() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    print(f'epoch: {epoch+1}, weight : {w:.3f}, loss ={l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {forward(5):.3f}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0., requires_grad=True)\n",
            "Prediction before training : f(5) = 0.000\n",
            "tensor(-30.)\n",
            "epoch: 1, weight : 0.300, loss =30.00000000\n",
            "tensor(-25.5000)\n",
            "tensor(-21.6750)\n",
            "tensor(-18.4238)\n",
            "tensor(-15.6602)\n",
            "tensor(-13.3112)\n",
            "tensor(-11.3145)\n",
            "tensor(-9.6173)\n",
            "tensor(-8.1747)\n",
            "tensor(-6.9485)\n",
            "tensor(-5.9062)\n",
            "epoch: 11, weight : 1.665, loss =1.16278565\n",
            "tensor(-5.0203)\n",
            "tensor(-4.2673)\n",
            "tensor(-3.6272)\n",
            "tensor(-3.0831)\n",
            "tensor(-2.6206)\n",
            "tensor(-2.2275)\n",
            "tensor(-1.8934)\n",
            "tensor(-1.6094)\n",
            "tensor(-1.3680)\n",
            "tensor(-1.1628)\n",
            "epoch: 21, weight : 1.934, loss =0.04506890\n",
            "tensor(-0.9884)\n",
            "tensor(-0.8401)\n",
            "tensor(-0.7141)\n",
            "tensor(-0.6070)\n",
            "tensor(-0.5159)\n",
            "tensor(-0.4385)\n",
            "tensor(-0.3728)\n",
            "tensor(-0.3168)\n",
            "tensor(-0.2693)\n",
            "tensor(-0.2289)\n",
            "epoch: 31, weight : 1.987, loss =0.00174685\n",
            "tensor(-0.1946)\n",
            "tensor(-0.1654)\n",
            "tensor(-0.1406)\n",
            "tensor(-0.1195)\n",
            "tensor(-0.1016)\n",
            "tensor(-0.0863)\n",
            "tensor(-0.0734)\n",
            "tensor(-0.0624)\n",
            "tensor(-0.0530)\n",
            "tensor(-0.0451)\n",
            "epoch: 41, weight : 1.997, loss =0.00006770\n",
            "tensor(-0.0383)\n",
            "tensor(-0.0326)\n",
            "tensor(-0.0277)\n",
            "tensor(-0.0235)\n",
            "tensor(-0.0200)\n",
            "tensor(-0.0170)\n",
            "tensor(-0.0144)\n",
            "tensor(-0.0123)\n",
            "tensor(-0.0104)\n",
            "tensor(-0.0089)\n",
            "epoch: 51, weight : 1.999, loss =0.00000262\n",
            "tensor(-0.0075)\n",
            "tensor(-0.0064)\n",
            "tensor(-0.0054)\n",
            "tensor(-0.0046)\n",
            "tensor(-0.0039)\n",
            "tensor(-0.0033)\n",
            "tensor(-0.0028)\n",
            "tensor(-0.0024)\n",
            "tensor(-0.0021)\n",
            "tensor(-0.0017)\n",
            "epoch: 61, weight : 2.000, loss =0.00000010\n",
            "tensor(-0.0015)\n",
            "tensor(-0.0013)\n",
            "tensor(-0.0011)\n",
            "tensor(-0.0009)\n",
            "tensor(-0.0008)\n",
            "tensor(-0.0007)\n",
            "tensor(-0.0006)\n",
            "tensor(-0.0005)\n",
            "tensor(-0.0004)\n",
            "tensor(-0.0003)\n",
            "epoch: 71, weight : 2.000, loss =0.00000000\n",
            "tensor(-0.0003)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0002)\n",
            "tensor(-0.0001)\n",
            "tensor(-0.0001)\n",
            "tensor(-9.2983e-05)\n",
            "tensor(-7.8678e-05)\n",
            "tensor(-6.6340e-05)\n",
            "epoch: 81, weight : 2.000, loss =0.00000000\n",
            "tensor(-5.5254e-05)\n",
            "tensor(-4.6849e-05)\n",
            "tensor(-3.8981e-05)\n",
            "tensor(-3.3796e-05)\n",
            "tensor(-2.8610e-05)\n",
            "tensor(-2.4676e-05)\n",
            "tensor(-2.1458e-05)\n",
            "tensor(-1.8239e-05)\n",
            "tensor(-1.4305e-05)\n",
            "tensor(-1.2338e-05)\n",
            "epoch: 91, weight : 2.000, loss =0.00000000\n",
            "tensor(-1.0371e-05)\n",
            "tensor(-9.1195e-06)\n",
            "tensor(-7.1526e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "tensor(-5.1856e-06)\n",
            "Prediction after training : f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWWlHKor58OF",
        "colab_type": "text"
      },
      "source": [
        "# Add optimizer,nn.Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjhY6JHvB0S8",
        "colab_type": "code",
        "outputId": "eaba2b1e-d669-40e2-cc0a-9ec74f1cb275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "# test sample\n",
        "X_test = torch.tensor([5],dtype = torch.float32)\n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# Loss\n",
        "loss = nn.MSELoss() \n",
        "\n",
        "# optimzie the weights\n",
        "# bias all included\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "  print(w.grad)\n",
        "\n",
        "  # update weights\n",
        "  optimizer.step()\n",
        "  \n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  w.grad.zero_() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    [w,b] = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w[0][0].item():.3f}, loss ={l:.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n",
            "Prediction before training : f(5) = -5.005\n",
            "tensor(0.)\n",
            "epoch: 1, weight : -0.407, loss =71.58859253\n",
            "tensor([[-38.5890]])\n",
            "tensor([[-32.1492]])\n",
            "tensor([[-26.7849]])\n",
            "tensor([[-22.3165]])\n",
            "tensor([[-18.5943]])\n",
            "tensor([[-15.4937]])\n",
            "tensor([[-12.9109]])\n",
            "tensor([[-10.7594]])\n",
            "tensor([[-8.9673]])\n",
            "tensor([[-7.4744]])\n",
            "epoch: 11, weight : 1.533, loss =1.86503279\n",
            "tensor([[-6.2308]])\n",
            "tensor([[-5.1949]])\n",
            "tensor([[-4.3320]])\n",
            "tensor([[-3.6132]])\n",
            "tensor([[-3.0144]])\n",
            "tensor([[-2.5156]])\n",
            "tensor([[-2.1001]])\n",
            "tensor([[-1.7540]])\n",
            "tensor([[-1.4656]])\n",
            "tensor([[-1.2255]])\n",
            "epoch: 21, weight : 1.848, loss =0.06036882\n",
            "tensor([[-1.0254]])\n",
            "tensor([[-0.8587]])\n",
            "tensor([[-0.7198]])\n",
            "tensor([[-0.6041]])\n",
            "tensor([[-0.5077]])\n",
            "tensor([[-0.4274]])\n",
            "tensor([[-0.3605]])\n",
            "tensor([[-0.3048]])\n",
            "tensor([[-0.2583]])\n",
            "tensor([[-0.2196]])\n",
            "epoch: 31, weight : 1.901, loss =0.01297265\n",
            "tensor([[-0.1874]])\n",
            "tensor([[-0.1605]])\n",
            "tensor([[-0.1381]])\n",
            "tensor([[-0.1194]])\n",
            "tensor([[-0.1038]])\n",
            "tensor([[-0.0909]])\n",
            "tensor([[-0.0800]])\n",
            "tensor([[-0.0710]])\n",
            "tensor([[-0.0635]])\n",
            "tensor([[-0.0572]])\n",
            "epoch: 41, weight : 1.911, loss =0.01108223\n",
            "tensor([[-0.0519]])\n",
            "tensor([[-0.0475]])\n",
            "tensor([[-0.0439]])\n",
            "tensor([[-0.0408]])\n",
            "tensor([[-0.0382]])\n",
            "tensor([[-0.0361]])\n",
            "tensor([[-0.0343]])\n",
            "tensor([[-0.0328]])\n",
            "tensor([[-0.0315]])\n",
            "tensor([[-0.0304]])\n",
            "epoch: 51, weight : 1.915, loss =0.01040784\n",
            "tensor([[-0.0295]])\n",
            "tensor([[-0.0287]])\n",
            "tensor([[-0.0281]])\n",
            "tensor([[-0.0275]])\n",
            "tensor([[-0.0270]])\n",
            "tensor([[-0.0266]])\n",
            "tensor([[-0.0263]])\n",
            "tensor([[-0.0260]])\n",
            "tensor([[-0.0257]])\n",
            "tensor([[-0.0255]])\n",
            "epoch: 61, weight : 1.918, loss =0.00980125\n",
            "tensor([[-0.0253]])\n",
            "tensor([[-0.0251]])\n",
            "tensor([[-0.0249]])\n",
            "tensor([[-0.0248]])\n",
            "tensor([[-0.0246]])\n",
            "tensor([[-0.0245]])\n",
            "tensor([[-0.0244]])\n",
            "tensor([[-0.0243]])\n",
            "tensor([[-0.0242]])\n",
            "tensor([[-0.0241]])\n",
            "epoch: 71, weight : 1.920, loss =0.00923077\n",
            "tensor([[-0.0240]])\n",
            "tensor([[-0.0239]])\n",
            "tensor([[-0.0238]])\n",
            "tensor([[-0.0237]])\n",
            "tensor([[-0.0236]])\n",
            "tensor([[-0.0236]])\n",
            "tensor([[-0.0235]])\n",
            "tensor([[-0.0234]])\n",
            "tensor([[-0.0233]])\n",
            "tensor([[-0.0233]])\n",
            "epoch: 81, weight : 1.923, loss =0.00869349\n",
            "tensor([[-0.0232]])\n",
            "tensor([[-0.0231]])\n",
            "tensor([[-0.0230]])\n",
            "tensor([[-0.0230]])\n",
            "tensor([[-0.0229]])\n",
            "tensor([[-0.0228]])\n",
            "tensor([[-0.0228]])\n",
            "tensor([[-0.0227]])\n",
            "tensor([[-0.0226]])\n",
            "tensor([[-0.0225]])\n",
            "epoch: 91, weight : 1.925, loss =0.00818749\n",
            "tensor([[-0.0225]])\n",
            "tensor([[-0.0224]])\n",
            "tensor([[-0.0223]])\n",
            "tensor([[-0.0223]])\n",
            "tensor([[-0.0222]])\n",
            "tensor([[-0.0221]])\n",
            "tensor([[-0.0221]])\n",
            "tensor([[-0.0220]])\n",
            "tensor([[-0.0219]])\n",
            "Prediction after training : f(5) = 9.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7is8wXS6E9O",
        "colab_type": "text"
      },
      "source": [
        "# Add nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVc-QVxmkPEd",
        "colab_type": "code",
        "outputId": "81d003b9-bed0-4930-e53a-d807ef9a9cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#1) Design model ( input, output size, forward pass )\n",
        "#2) Construct loss and optimizer\n",
        "#3) Training loop\n",
        "#forward pass : compute prediction\n",
        "#backward pass : gradients\n",
        "#update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([[5]],dtype = torch.float32)\n",
        "n_samples,n_features = X.shape\n",
        "print(X.shape)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad=True) \n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# loss = MSE\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  #with torch.no_grad(): #ensure the gradient is not calculated\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  optimizer.zero_grad() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    w,b = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w.item():.3f}, loss ={l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "Prediction before training : f(5) = -1.751\n",
            "epoch: 1, weight : 0.151, loss =44.74452209\n",
            "epoch: 11, weight : 1.684, loss =1.15837872\n",
            "epoch: 21, weight : 1.931, loss =0.03065797\n",
            "epoch: 31, weight : 1.971, loss =0.00144119\n",
            "epoch: 41, weight : 1.978, loss =0.00064757\n",
            "epoch: 51, weight : 1.980, loss =0.00059152\n",
            "epoch: 61, weight : 1.980, loss =0.00055661\n",
            "epoch: 71, weight : 1.981, loss =0.00052421\n",
            "epoch: 81, weight : 1.982, loss =0.00049369\n",
            "epoch: 91, weight : 1.982, loss =0.00046496\n",
            "Prediction after training : f(5) = 9.964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV9dUVPf7Ryi",
        "colab_type": "text"
      },
      "source": [
        "# Add Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lojngyRssEnk",
        "colab_type": "code",
        "outputId": "2605956d-6fcc-42fb-f590-f7392764c869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#1) Design model ( input, output size, forward pass )\n",
        "#2) Construct loss and optimizer\n",
        "#3) Training loop\n",
        "#forward pass : compute prediction\n",
        "#backward pass : gradients\n",
        "#update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#np.random.seed(42)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "# bias are taken care of\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype = torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([[5]],dtype = torch.float32)\n",
        "n_samples,n_features = X.shape\n",
        "print(X.shape)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "#model = nn.Linear(input_size,output_size)\n",
        "\n",
        "#initialize the weight\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad=True) \n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self,input_dim,output_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim,output_dim)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size,output_size)\n",
        "\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# loss = MSE\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_hat = model(X)\n",
        "  \n",
        "  # loss\n",
        "  l=loss(Y,y_hat)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  #with torch.no_grad(): #ensure the gradient is not calculated\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero the gradients to ensure it's not accumulated\n",
        "  optimizer.zero_grad() #reset zero\n",
        "\n",
        "  if epoch % 10==0:\n",
        "    w,b = model.parameters()\n",
        "    print(f'epoch: {epoch+1}, weight : {w.item():.3f}, loss ={l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "Prediction before training : f(5) = -0.745\n",
            "epoch: 1, weight : 0.229, loss =35.72889709\n",
            "epoch: 11, weight : 1.601, loss =0.95077527\n",
            "epoch: 21, weight : 1.825, loss =0.04944678\n",
            "epoch: 31, weight : 1.864, loss =0.02468096\n",
            "epoch: 41, weight : 1.874, loss =0.02267811\n",
            "epoch: 51, weight : 1.879, loss =0.02134349\n",
            "epoch: 61, weight : 1.882, loss =0.02010081\n",
            "epoch: 71, weight : 1.886, loss =0.01893084\n",
            "epoch: 81, weight : 1.889, loss =0.01782896\n",
            "epoch: 91, weight : 1.892, loss =0.01679120\n",
            "Prediction after training : f(5) = 9.784\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}