{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Logistic Regression Wine  Dataset DataLoader",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0wV/DoVNtu2hmeGvcTiYE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHuQQfqo9uBc",
        "colab_type": "text"
      },
      "source": [
        "# Logistic  Regression\n",
        "\n",
        "### Step by step <p>\n",
        "1) Design model ( input, output size, forward pass )<p>\n",
        "2) Construct loss and optimizer<p>\n",
        "3) Training loop<p>\n",
        "\n",
        "- forward pass : compute prediction\n",
        "- backward pass : gradients\n",
        "- update weights\n",
        "\n",
        "### General Steps <p>\n",
        "0) prepare data <p>\n",
        "1) Model <p>\n",
        "2) loss and optimizer <p>\n",
        "3) training loop <p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoFO9dV09tEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AJNE1TrR-cGZ"
      },
      "source": [
        "Dataset and DataLoader - Batch Training\n",
        "\n",
        "gradient computation etc. not efficient for whole data set\n",
        " -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "\n",
        "epoch = one forward and backward pass of ALL training samples<p>\n",
        "batch_size = number of training samples used in one forward/backward pass<p>\n",
        "number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of samples<p>\n",
        "e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbKFYHVTHyOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynwq_MVfasy",
        "colab_type": "code",
        "outputId": "60e6164c-6141-48e0-cd10-6bb9a2c0644f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    file = 'https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv'\n",
        "    xy = np.loadtxt(file,delimiter =\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y = torch.from_numpy(xy[:,[0]])\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "#first_data = dataset[0]\n",
        "#features,labels = first_data\n",
        "batch_size = 4\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=batch_size,shuffle=True,num_workers = 2)\n",
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels = data\n",
        "print(features,labels)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "learning_rate = 0.01\n",
        "n_iterations = math.ceil(total_samples/batch_size)\n",
        "print(total_samples,n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for iter,(inputs,labels) in enumerate(dataloader):\n",
        "    # forward, backward, update\n",
        "    if (iter+1) % 5==0:\n",
        "      print(f'epoch :{epoch+1}/{num_epochs},step :{iter+1}/{len(dataloader)},inputs :{inputs.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.3560e+01, 1.7300e+00, 2.4600e+00, 2.0500e+01, 1.1600e+02, 2.9600e+00,\n",
            "         2.7800e+00, 2.0000e-01, 2.4500e+00, 6.2500e+00, 9.8000e-01, 3.0300e+00,\n",
            "         1.1200e+03],\n",
            "        [1.3450e+01, 3.7000e+00, 2.6000e+00, 2.3000e+01, 1.1100e+02, 1.7000e+00,\n",
            "         9.2000e-01, 4.3000e-01, 1.4600e+00, 1.0680e+01, 8.5000e-01, 1.5600e+00,\n",
            "         6.9500e+02],\n",
            "        [1.1790e+01, 2.1300e+00, 2.7800e+00, 2.8500e+01, 9.2000e+01, 2.1300e+00,\n",
            "         2.2400e+00, 5.8000e-01, 1.7600e+00, 3.0000e+00, 9.7000e-01, 2.4400e+00,\n",
            "         4.6600e+02],\n",
            "        [1.2850e+01, 1.6000e+00, 2.5200e+00, 1.7800e+01, 9.5000e+01, 2.4800e+00,\n",
            "         2.3700e+00, 2.6000e-01, 1.4600e+00, 3.9300e+00, 1.0900e+00, 3.6300e+00,\n",
            "         1.0150e+03]]) tensor([[1.],\n",
            "        [3.],\n",
            "        [2.],\n",
            "        [1.]])\n",
            "178 45\n",
            "epoch :1/2,step :5/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :10/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :15/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :20/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :25/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :30/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :35/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :40/45,inputs :torch.Size([4, 13])\n",
            "epoch :1/2,step :45/45,inputs :torch.Size([2, 13])\n",
            "epoch :2/2,step :5/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :10/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :15/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :20/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :25/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :30/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :35/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :40/45,inputs :torch.Size([4, 13])\n",
            "epoch :2/2,step :45/45,inputs :torch.Size([2, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TeP_KHEYXeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}